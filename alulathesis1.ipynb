{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wisamabdullah85/PythonHacks/blob/main/alulathesis1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KMNBV4lU8UX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# قراءة الصور وتحويلها إلى تمثيل BGR وتحويلها إلى الحجم المطلوب\n",
        "def preprocess_images(image_folder, target_size=(128, 128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for folder_name in os.listdir(image_folder):\n",
        "        folder_path = os.path.join(image_folder, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            label = folder_name\n",
        "            for filename in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.resize(img, target_size)\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n"
      ],
      "metadata": {
        "id": "ux3zWp4QVron"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تطبيق تقنية LDA\n",
        "def apply_lda(images, labels, n_components=2):\n",
        "    lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
        "    lda.fit(images.reshape(len(images), -1), labels)\n",
        "    return lda.transform(images.reshape(len(images), -1))"
      ],
      "metadata": {
        "id": "o27hI7P8Vzk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تحميل نموذج VGG16\n",
        "def load_vgg16(input_shape=(128, 128, 3), output_shape=7):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    predictions = Dense(output_shape, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "zTBgWmO1V5fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for directory in dirs:\n",
        "            class_path = os.path.join(root, directory)\n",
        "            for file_name in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, file_name)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is not None:\n",
        "                    images.append(image)\n",
        "                    labels.append(directory)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "UfnqENE1tWSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# مسار المجلد الرئيسي الذي يحتوي على مجلدات التدريب والاختبار والتحقق\n",
        "dataset_path = \"D:/mod/\"\n"
      ],
      "metadata": {
        "id": "dAKQubp6taiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تحميل البيانات من مجلدات التدريب والاختبار والتحقق\n",
        "train_images, train_labels = load_dataset(os.path.join(dataset_path, \"CaS\"))\n"
      ],
      "metadata": {
        "id": "WVCuMNbZtzk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# التحقق من وجود صور في مجموعة التدريب قبل التقسيم\n",
        "if len(train_images) > 0:\n",
        "    # تقسيم البيانات إلى مجموعات التدريب والاختبار والتحقق\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "Mr7kbZQHuHYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# عدد الصور الكلي\n",
        "total_images = 5143\n"
      ],
      "metadata": {
        "id": "n-EiS3L5v3Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# نسب التقسيم\n",
        "train_ratio = 0.60\n",
        "validation_ratio = 0.20\n",
        "test_ratio = 0.20\n"
      ],
      "metadata": {
        "id": "0Uweq3tjv-dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# حساب عدد الصور لكل مجموعة\n",
        "train_count = int(total_images * train_ratio)\n",
        "validation_count = int(total_images * validation_ratio)\n",
        "test_count = int(total_images * test_ratio)\n"
      ],
      "metadata": {
        "id": "N5aXqKKuw5Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# طباعة عدد الصور لكل مجموعة\n",
        "print(\"عدد الصور في مجموعة التدريب:\", train_count)\n",
        "print(\"عدد الصور في مجموعة التحقق:\", validation_count)\n",
        "print(\"عدد الصور في مجموعة الاختبار:\", test_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyMoTAKkw7AN",
        "outputId": "1e0d8930-ab2e-48cf-bd4c-065e218f064c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "عدد الصور في مجموعة التدريب: 3085\n",
            "عدد الصور في مجموعة التحقق: 1028\n",
            "عدد الصور في مجموعة الاختبار: 1028\n"
          ]
        }
      ]
    }
  ]
}